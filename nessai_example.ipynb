{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using nessai\n",
    "\n",
    "This notebooks shows an example of using `nessai` for Bayesian inference.\n",
    "\n",
    "For more details about nessai see: https://nessai.readthedocs.io/\n",
    "\n",
    "If you want to try this example locally `nessai` can be installed using `pip`:\n",
    "\n",
    "```python\n",
    "pip install nessai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "from nessai.flowsampler import FlowSampler\n",
    "from nessai.model import Model\n",
    "from nessai.utils import setup_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going set up a logger to log the output from `nessai`, this is based on the implementation in `bilby`.\n",
    "\n",
    "See: https://git.ligo.org/lscsoft/bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = './output/'\n",
    "logger = setup_logger(log_level='WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    " \n",
    "In this case we're using a simple 2-dimensionl Gaussian since it will run relatively quickly. \n",
    "\n",
    "The model must contain names for each of the parameters and their prior bounds as a dictionary with arrays/lists with the mininimum and maximum.\n",
    "\n",
    "The main functions in the model should be the `log_prior` and l`og_likelihood`. \n",
    "\n",
    "The log prior must be able to accept structed arrays of points where each field is one of the names in the model and there are two extra fields which are `logP` and `logL`. The log-likelihood should accept the same inputs as the prior and return the log-likelihood of the given point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianModel(Model):\n",
    "    \"\"\"\n",
    "    A simple two-dimensional Guassian likelihood\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Names of parameters to sample\n",
    "        self.names = ['x0', 'x1']\n",
    "        # Prior bounds for each parameter\n",
    "        self.bounds = {n: [-10, 10] for n in self.names}\n",
    "\n",
    "    def log_prior(self, x):\n",
    "        \"\"\"\n",
    "        Returns log of prior given a live point assuming uniforn\n",
    "        priors on each parameter.\n",
    "        \n",
    "        Also checks the points are within the prior bounds.\n",
    "        \"\"\"\n",
    "        log_p = 0.\n",
    "        # Iterate through each parameter (x and y)\n",
    "        # since the live points are a structured array we can\n",
    "        # get each value using just the name\n",
    "        for n in self.names:\n",
    "            log_p += (np.log((x[n] >= self.bounds[n][0])\n",
    "                             & (x[n] <= self.bounds[n][1]))\n",
    "                      - np.log(self.bounds[n][1] - self.bounds[n][0]))\n",
    "        return log_p\n",
    "\n",
    "    def log_likelihood(self, x):\n",
    "        \"\"\"\n",
    "        Returns log likelihood of given live point assuming a Gaussian\n",
    "        likelihood.\n",
    "        \"\"\"\n",
    "        log_l = 0\n",
    "        # Use a Guassian logpdf and iterate through the parameters\n",
    "        for pn in self.names:\n",
    "            log_l += norm.logpdf(x[pn])\n",
    "        return log_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring `nessai`\n",
    "\n",
    "There are two aspects to configure in `nessai`: the normalising flow and the actual sampler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the normalisng flow\n",
    "\n",
    "The normalsing flow that is trained to produce the proposal points is configured with a dictionary that contains the parameters related to training (e.g. learning rate (lr)) and `model_config` for the configuring\n",
    "the flow itself (neurons, number of trasformations, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_config = dict(\n",
    "    max_epochs=50,\n",
    "    patience=10,\n",
    "    model_config=dict(\n",
    "        n_blocks=2,    # Use two transforms\n",
    "        n_layers=1,    # Use 1 layer in the NN in each transform\n",
    "        n_neurons=4,   # Use 4 neurons per layer\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the samper\n",
    "\n",
    "The `FlowSampler` object is used to managed the sampling settings, run and resume the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FlowSampler(\n",
    "    GaussianModel(),           # The model\n",
    "    output=output,             # Output directory\n",
    "    nlive=2000,                # Number of live points\n",
    "    maximum_uninformed=2000,   # Maximum number of iterations before the flow is trained\n",
    "    flow_config=flow_config,   # Configuration for the flow\n",
    "    resume=False,              # Don't resume the previous run\n",
    "    seed=1234                  # Set a random seed, this also seeds `torch`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run the sampler.\n",
    "\n",
    "Whilst running the sampler will print statistics that describe it's current state. We normally focus on `dZ` since by default the sampler will stop when `dZ<=0.1`.\n",
    "\n",
    "Also, notice how p-values are periodically printed. This is an indication of whether the insertion indices are uniformly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instance of `FlowSampler` contains the actual nested sampler that has some useful methods that we can use to produce some diagnostic plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace plot\n",
    "\n",
    "A trace plot is standard way to examine how the sample explored the parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = fs.ns.plot_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State plot\n",
    "\n",
    "This plot shows us the evolution of the sampler by interation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = fs.ns.plot_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion indices\n",
    "\n",
    "We can also check the insertion indices, they should be approximatly uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = fs.ns.plot_insertion_indices()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nessai)",
   "language": "python",
   "name": "nessai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
