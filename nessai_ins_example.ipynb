{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using ins-nessai\n",
    "\n",
    "**Warning** This notebook demonstrates experimental API in nessai that may change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "We start by installing a bleeding edge version of nessai directly from GitHub.\n",
    "\n",
    "\n",
    "**Warning:** this version of nessai is bleeding edge and subject to changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/mj-will/nessai.git@stable-ins --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nessai.flowsampler import FlowSampler\n",
    "from nessai.model import Model\n",
    "from nessai.plot import corner_plot\n",
    "from nessai.utils import setup_logger\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the output directory and configure the logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"ins_example\"\n",
    "setup_logger(output=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "\n",
    "As per usual we, define model which contains the log-likelihood and log-prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rosenbrock(Model):\n",
    "    \"\"\"A Rosenbrock model\"\"\"\n",
    "\n",
    "    def __init__(self, dims: int = 2) -> None:\n",
    "        self.names = [f\"x_{i}\" for i in range(dims)]\n",
    "        self.bounds = {n: [-5, 5] for n in self.names}\n",
    "\n",
    "    def log_likelihood(self, x):\n",
    "        \"\"\"Log-likelihood function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray\n",
    "            Array of samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Array of log-probabilities.\n",
    "        \"\"\"\n",
    "        # We get an unstructured view of the structured input array. This\n",
    "        # allows use to vectorise the likelihood calculation.\n",
    "        x = self.unstructured_view(x)\n",
    "        return -np.sum(\n",
    "            100. * (x[..., 1:] - x[..., :-1] ** 2.0) ** 2.0\n",
    "            + (1.0 - x[..., :-1]) ** 2.0,\n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "    def log_prior(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Log probability for a uniform prior.\n",
    "\n",
    "        Also checks if samples are within the prior bounds.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray\n",
    "            Array of samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Array of log-probabilities.\n",
    "        \"\"\"\n",
    "        # Check if the points are within the prior bounds\n",
    "        log_p = np.log(self.in_bounds(x), dtype=float)\n",
    "        # Compute the log-prior probability\n",
    "        log_p -= np.sum(np.log(self.upper_bounds - self.lower_bounds))\n",
    "        return log_p\n",
    "\n",
    "    def to_unit_hypercube(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Convert the samples to the unit-hypercube.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray\n",
    "            Array of samples.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Array of rescaled samples.\n",
    "        \"\"\"\n",
    "        x_out = x.copy()\n",
    "        for n in self.names:\n",
    "            x_out[n] = (\n",
    "                (x[n] - self.bounds[n][0])\n",
    "                / (self.bounds[n][1] - self.bounds[n][0])\n",
    "            )\n",
    "        return x_out\n",
    "\n",
    "    def from_unit_hypercube(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Convert samples from the unit-hypercube to the prior space.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray\n",
    "            Array of samples in the unit-hypercube.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.ndarray\n",
    "            Array of sample in the prior space.\n",
    "        \"\"\"\n",
    "        x_out = x.copy()\n",
    "        for n in self.names:\n",
    "            x_out[n] = (\n",
    "                (self.bounds[n][1] - self.bounds[n][0])\n",
    "                * x[n] + self.bounds[n][0]\n",
    "            )\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Rosenbrock(dims=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the sampler\n",
    "\n",
    "We run the importance nested sampler the same way we run that standard nested sampler in `nessai`, the only difference is we need to set `importance_nested_sampler=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = FlowSampler(\n",
    "    model,\n",
    "    output=output,\n",
    "    nlive=2000,\n",
    "    importance_nested_sampler=True,  # Use the importance nested sampler\n",
    "    resume=False,  # Avoid resuming\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The reults are saved in the output directory, by default this includes plots as well. However, we can also visualise some of the results directly in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Final ln-evidence: {sampler.log_evidence:.3f} +/- {sampler.log_evidence_error:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner_plot(sampler.posterior_samples, include=model.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "\n",
    "We can also look at some of the diagnostic plots that are produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace plot\n",
    "\n",
    "Since the prior-volume (X) is not computed, we can't produce a traditional trace plot. However, we can plot samples against $\\log (\\pi / Q)$ which is refered to as `logW` in the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sampler.ns.plot_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State plot\n",
    "\n",
    "We can also produce a **state** plot which that state of the sampler at each iteration. If plotting is enabled, this plot is produce during the run and can be useful for understanding the current state of the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sampler.ns.plot_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nessai)",
   "language": "python",
   "name": "nessai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
